{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "casting-surface-quality-prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D3bRHBp8vXhV"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Link to file download(maybe need to login on kaggle)](https://www.kaggle.com/datasets/ravirajsinh45/real-life-industrial-dataset-of-casting-product)"
      ],
      "metadata": {
        "id": "DVr6huOE0uXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_extraction = zipfile.ZipFile(\"casting-product-quality-dataset-kaggle.zip\")\n",
        "zip_file_extraction.extractall()\n",
        "zip_file_extraction.close()"
      ],
      "metadata": {
        "id": "Klu7S-ZFvykF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls casting_512x512/casting_512x512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqzT85pYwWd6",
        "outputId": "31919061-48d6-4683-89f4-09be43f87e8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def_front  ok_front\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for dirpath, dirnames, filenames in os.walk(\"casting_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9r-VuiC3d3c",
        "outputId": "334d87ff-2493-48cc-b2cc-052d3c1aaa89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 directories and 0 images in 'casting_data'.\n",
            "There are 2 directories and 0 images in 'casting_data/casting_data'.\n",
            "There are 2 directories and 0 images in 'casting_data/casting_data/train'.\n",
            "There are 0 directories and 3758 images in 'casting_data/casting_data/train/def_front'.\n",
            "There are 0 directories and 2875 images in 'casting_data/casting_data/train/ok_front'.\n",
            "There are 2 directories and 0 images in 'casting_data/casting_data/test'.\n",
            "There are 0 directories and 453 images in 'casting_data/casting_data/test/def_front'.\n",
            "There are 0 directories and 262 images in 'casting_data/casting_data/test/ok_front'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Setup the train and test directories\n",
        "train_dir = \"casting_data/casting_data/train/\"\n",
        "test_dir = \"casting_data/casting_data/test/\"\n",
        "\n",
        "# Import data from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               batch_size=32, # number of images to process at a time \n",
        "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
        "                                               class_mode=\"binary\", # type of problem we're working on\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(test_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "# Create a CNN model (same as Tiny VGG - https://poloclub.github.io/cnn-explainer/)\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=10, \n",
        "                         kernel_size=3, # can also be (3, 3)\n",
        "                         activation=\"relu\", \n",
        "                         input_shape=(224, 224, 3)), # first layer specifies input shape (height, width, colour channels)\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
        "                            padding=\"valid\"), # padding can also be 'same'\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
        "  tf.keras.layers.MaxPool2D(2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\") # binary activation output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GCtgk9D3qGp",
        "outputId": "d5addbd4-ad4b-4f19-bfa1-a44378e216da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6633 images belonging to 2 classes.\n",
            "Found 715 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "208/208 [==============================] - 31s 91ms/step - loss: 0.5113 - accuracy: 0.7460 - val_loss: 0.3168 - val_accuracy: 0.8783\n",
            "Epoch 2/5\n",
            "208/208 [==============================] - 19s 91ms/step - loss: 0.2577 - accuracy: 0.8991 - val_loss: 0.2089 - val_accuracy: 0.9147\n",
            "Epoch 3/5\n",
            "208/208 [==============================] - 18s 89ms/step - loss: 0.1568 - accuracy: 0.9447 - val_loss: 0.0973 - val_accuracy: 0.9720\n",
            "Epoch 4/5\n",
            "208/208 [==============================] - 19s 89ms/step - loss: 0.0989 - accuracy: 0.9705 - val_loss: 0.2318 - val_accuracy: 0.8825\n",
            "Epoch 5/5\n",
            "208/208 [==============================] - 19s 90ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 0.1234 - val_accuracy: 0.9552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijIQphMaF-kP",
        "outputId": "6644be0a-c9c4-4ea1-8c8e-07bfc36c4fe9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 10)      280       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 220, 220, 10)      910       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 110, 110, 10)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 108, 108, 10)      910       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 106, 106, 10)      910       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 53, 53, 10)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 28090)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 28091     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,101\n",
            "Trainable params: 31,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Setup the train and test directories\n",
        "train_dir = \"casting_data/casting_data/train/\"\n",
        "test_dir = \"casting_data/casting_data/test/\"\n",
        "\n",
        "# Import data from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               batch_size=16, # number of images to process at a time \n",
        "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
        "                                               class_mode=\"binary\", # type of problem we're working on\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(test_dir,\n",
        "                                               batch_size=16,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "# Create a CNN model (same as Tiny VGG - https://poloclub.github.io/cnn-explainer/)\n",
        "model_2 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=15, \n",
        "                         kernel_size=3, # can also be (3, 3)\n",
        "                         activation=\"relu\", \n",
        "                         input_shape=(224, 224, 3)), # first layer specifies input shape (height, width, colour channels)\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
        "                            padding=\"valid\"), # padding can also be 'same'\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
        "  tf.keras.layers.MaxPool2D(2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\") # binary activation output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_2 = model_2.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrr30NkRHMWb",
        "outputId": "13094691-05c8-402e-b447-883a2b63bde2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6633 images belonging to 2 classes.\n",
            "Found 715 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "415/415 [==============================] - 20s 46ms/step - loss: 0.5118 - accuracy: 0.7338 - val_loss: 0.3021 - val_accuracy: 0.8979\n",
            "Epoch 2/5\n",
            "415/415 [==============================] - 19s 46ms/step - loss: 0.1957 - accuracy: 0.9278 - val_loss: 0.1549 - val_accuracy: 0.9357\n",
            "Epoch 3/5\n",
            "415/415 [==============================] - 19s 45ms/step - loss: 0.1142 - accuracy: 0.9614 - val_loss: 0.0923 - val_accuracy: 0.9692\n",
            "Epoch 4/5\n",
            "415/415 [==============================] - 19s 46ms/step - loss: 0.0832 - accuracy: 0.9739 - val_loss: 0.0480 - val_accuracy: 0.9846\n",
            "Epoch 5/5\n",
            "415/415 [==============================] - 19s 45ms/step - loss: 0.0621 - accuracy: 0.9815 - val_loss: 0.0523 - val_accuracy: 0.9776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZaMXZ2QHxF8",
        "outputId": "1c7a419e-4b96-4b6b-8569-80936a6f745f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 222, 222, 15)      420       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 220, 220, 10)      1360      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 110, 110, 10)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 108, 108, 10)      910       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 106, 106, 10)      910       \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 104, 104, 10)      910       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 52, 52, 10)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 27040)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 27041     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,551\n",
            "Trainable params: 31,551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3Mm7uyAoJuNH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}